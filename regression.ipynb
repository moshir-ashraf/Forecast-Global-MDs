{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def visualizeSCF(feature, name):  # SCF = Single Categorical feature\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x=feature)\n",
    "    plt.title('Countplot for: ', name)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualizeSNF(feature, name):  # SNF = Single Numerical feature\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(x=feature, kde=True, bins=100)\n",
    "    plt.title(f'Histogram for: {name}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models & Transformers\n",
    "encoder = LabelEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectOutliersIqr(feature):\n",
    "    print(\"Before detectOutliersIqr\")\n",
    "    Q1 = np.percentile(feature, 25)\n",
    "    Q3 = np.percentile(feature, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Set a threshold (1.5 * IQR)\n",
    "    threshold = 1.5\n",
    "    lowerBound = Q1 - threshold * IQR\n",
    "    upperBound = Q3 + threshold * IQR\n",
    "\n",
    "    # Find outliers\n",
    "    outliers = feature[(feature < lowerBound) | (feature > upperBound)]\n",
    "    outlierCount = len(outliers)\n",
    "    print(\"After detectOutliersIqr\")\n",
    "    return {\n",
    "        'featureName': feature.name,\n",
    "        'outlierIndices': outliers.index.tolist(),\n",
    "        'outlierCount': outlierCount\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformDate(features):\n",
    "    print(\"Before transformDate\")\n",
    "    features[['tempDate', 'time']] = features['date'].str.split(' ', n=1, expand=True)\n",
    "    features['tempDate'] = pd.to_datetime(features['tempDate'], format='%d/%m/%Y')\n",
    "    features['Month'] = features['tempDate'].dt.month\n",
    "    features['Hour'] = pd.to_datetime(features['time'], format='%H:%M').dt.hour\n",
    "    features['Minute'] = pd.to_datetime(features['time'], format='%H:%M').dt.minute\n",
    "    features['Day'] = features['tempDate'].dt.day_name()\n",
    "    print(\"After transformDate\")\n",
    "    return features.drop(['tempDate', 'date', 'time', 'Day_of_week'], axis=1)\n",
    "\n",
    "def findWeekStatus(features):\n",
    "    print(\"Before findWeekStatus\")\n",
    "    weekdays = ['Friday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday']\n",
    "    weekends = ['Saturday', 'Sunday']\n",
    "    indicies = features[features['WeekStatus'].isnull()].index\n",
    "    for index in indicies:\n",
    "        day = features.loc[index, 'Day']\n",
    "        if day in weekdays:\n",
    "            features.loc[index, 'WeekStatus'] = 'Weekday'\n",
    "        elif day in weekends:\n",
    "            features.loc[index, 'WeekStatus'] = 'Weekend'\n",
    "    print(\"After findWeekStatus\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transformDate\n",
      "After transformDate\n",
      "Before findWeekStatus\n",
      "After findWeekStatus\n",
      "Before transformDate\n",
      "After transformDate\n",
      "Before findWeekStatus\n",
      "After findWeekStatus\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "features = data.drop(['Id', 'Usage_kWh'], axis=1)\n",
    "target = data['Usage_kWh']\n",
    "features = transformDate(features)\n",
    "features = findWeekStatus(features)\n",
    "test = transformDate(test)\n",
    "test = findWeekStatus(test)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "xTest = test.drop('Id', axis=1)\n",
    "START_ID = 28000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (27999, 12)\n",
      "Data Description:                  Id  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "count  27999.00000                          27999.000000   \n",
      "mean   14000.00000                             13.230912   \n",
      "std     8082.75943                             16.469935   \n",
      "min        1.00000                              0.000000   \n",
      "25%     7000.50000                              2.740000   \n",
      "50%    14000.00000                              5.040000   \n",
      "75%    20999.50000                             22.820000   \n",
      "max    27999.00000                             96.910000   \n",
      "\n",
      "       Leading_Current_Reactive_Power_kVarh     CO2(tCO2)  \\\n",
      "count                          27880.000000  27999.000000   \n",
      "mean                               3.881065      0.011790   \n",
      "std                                7.495718      0.016354   \n",
      "min                                0.000000      0.000000   \n",
      "25%                                0.000000      0.000000   \n",
      "50%                                0.000000      0.000000   \n",
      "75%                                2.230000      0.020000   \n",
      "max                               27.760000      0.070000   \n",
      "\n",
      "       Lagging_Current_Power_Factor  Leading_Current_Power_Factor  \\\n",
      "count                  27999.000000                  27923.000000   \n",
      "mean                      79.940163                     84.479796   \n",
      "std                       19.397474                     30.422037   \n",
      "min                       36.940000                     12.500000   \n",
      "25%                       61.640000                     99.810000   \n",
      "50%                       87.990000                    100.000000   \n",
      "75%                       99.080000                    100.000000   \n",
      "max                      100.000000                    100.000000   \n",
      "\n",
      "                NSM     Usage_kWh  \n",
      "count  27999.000000  27999.000000  \n",
      "mean   42718.611379     27.888785  \n",
      "std    24933.404759     33.919271  \n",
      "min        0.000000      2.450000  \n",
      "25%    20700.000000      3.130000  \n",
      "50%    42300.000000      4.570000  \n",
      "75%    63900.000000     51.190000  \n",
      "max    85500.000000    153.140000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape: \", data.shape)\n",
    "print(\"Data Description: \",data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization & Preprocessing\n",
    "\n",
    "def encode(feature, xTrain, xVal, xTest):\n",
    "    print(\"Before encode\")\n",
    "    xTrain[feature] = encoder.fit_transform(xTrain[feature])\n",
    "    xVal[feature] = encoder.transform(xVal[feature])\n",
    "    xTest[feature] = encoder.transform(xTest[feature])\n",
    "    print(\"After encode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale(feature, xTrain, xVal, xTest):\n",
    "    print(\"Before scale\")\n",
    "    xTrain[feature] = scaler.fit_transform(xTrain[feature].values.reshape(-1, 1))\n",
    "    xVal[feature] = scaler.transform(xVal[feature].values.reshape(-1, 1))\n",
    "    xTest[feature] = scaler.transform(xTest[feature].values.reshape(-1, 1))\n",
    "    print(\"After scale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(feature, xTrain, xVal, xTest):\n",
    "    print(\"Before impute\")\n",
    "    xTrain[feature] = xTrain[feature].fillna(xTrain[feature].median())\n",
    "    xVal[feature] = xVal[feature].fillna(xTrain[feature].median())\n",
    "    xTest[feature] = xTest[feature].fillna(xTrain[feature].median())\n",
    "    print(\"After impute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(model, xTrain, yTrain,degree=0,):\n",
    "        trainSizes = np.linspace(0.1, 1.0, 10)\n",
    "        trainSizes, trainScores, valScores = learning_curve(\n",
    "            model, xTrain, yTrain, train_sizes=trainSizes, cv=5, scoring='r2'\n",
    "        )\n",
    "        trainScoresMean = np.mean(trainScores, axis=1)\n",
    "        trainScoresStd = np.std(trainScores, axis=1)\n",
    "        valScoresMean = np.mean(valScores, axis=1)\n",
    "        valScoresStd = np.std(valScores, axis=1)\n",
    "\n",
    "        # Plot learning curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.fill_between(trainSizes * len(xTrain), trainScoresMean - trainScoresStd,\n",
    "                         trainScoresMean + trainScoresStd, alpha=0.1, color=\"r\")\n",
    "        plt.fill_between(trainSizes * len(xTrain), valScoresMean - valScoresStd,\n",
    "                         valScoresMean + valScoresStd, alpha=0.1, color=\"g\")\n",
    "        plt.plot(trainSizes * len(xTrain), trainScoresMean, 'o-', color=\"r\", label=\"Training score\")\n",
    "        plt.plot(trainSizes * len(xTrain), valScoresMean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "        plt.xlabel(\"Number of training examples\")\n",
    "        plt.ylabel(\"R2 Score\")\n",
    "        if degree > 0:  plt.title(f\"Learning Curve for Polynomial Regression of Degree ({degree}) \")\n",
    "        else: plt.title(f\"Learning Curve for Linear Regression\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simpleLinearRegression(model, xTrain, yTrain, xVal, yVal):\n",
    "    print(\"Simple Linear Regression\")\n",
    "    learningCurve(model, xTrain, yTrain)\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    print(f\"Training R2 Score : {r2_score(yTrain, yPredTrain)}\")\n",
    "    print(f\"Training Mean Squared Error : {mean_squared_error(yTrain,yPredTrain)}\")\n",
    "    yPredVal = model.predict(xVal)\n",
    "    print(f\"Validation R2 Score : { r2_score(yVal, yPredVal)}\")\n",
    "    print(f\"Validation Mean Squared Error : {mean_squared_error(yVal,yPredVal)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ridgeRegularization(xTrain, yTrain, xVal, yVal):\n",
    "    alphas = [0.01, 0.1, 1.0, 10.0]  \n",
    "    bestR2 = -float('inf')\n",
    "    bestMSE = float('inf')\n",
    "    bestAlpha = None\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        ridge = Ridge(alpha=alpha, random_state=42)\n",
    "        print(f\"Ridge Regression with Regularization Parameter: {alpha}\")\n",
    "        _,r2, MSE = comparePolynomialDegrees(ridge, xTrain, yTrain, xVal, yVal)\n",
    "        \n",
    "        if r2 > bestR2:\n",
    "            bestR2 = r2\n",
    "            bestMSE = MSE\n",
    "            bestAlpha = alpha\n",
    "    \n",
    "    print(f\"Best Ridge Regularization Parameter (alpha): {bestAlpha}\")\n",
    "    print(f\"Ridge (alpha={bestAlpha}) R2 Score: {bestR2}\")\n",
    "    print(f\"Ridge (alpha={bestAlpha}) Mean Squared Error: {bestMSE}\")\n",
    "    return bestAlpha, bestR2, bestMSE\n",
    "    \n",
    "def lassoRegularization(xTrain, yTrain, xVal, yVal):\n",
    "    alphas = [0.01, 0.1, 1.0, 10.0]  \n",
    "    bestR2 = -float('inf')\n",
    "    bestMSE = float('inf')\n",
    "    bestAlpha = None\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        lasso = Lasso(alpha=alpha, random_state=42)\n",
    "        print(f\"Lasso Regression with Regularization Parameter: {alpha}\")\n",
    "        _,r2, MSE = comparePolynomialDegrees(lasso, xTrain, yTrain, xVal, yVal)\n",
    "        \n",
    "        if r2 > bestR2:\n",
    "            bestR2 = r2\n",
    "            bestMSE = MSE\n",
    "            bestAlpha = alpha\n",
    "    \n",
    "    print(f\"Best Lasso Regularization Parameter (alpha): {bestAlpha}\")\n",
    "    print(f\"Lasso (alpha={bestAlpha}) R2 Score: {bestR2}\")\n",
    "    print(f\"Lasso (alpha={bestAlpha}) Mean Squared Error: {bestMSE}\")\n",
    "    return bestAlpha, bestR2, bestMSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparePolynomialDegrees(model, xTrain, yTrain, xVal, yVal):\n",
    "    trainErrors = []\n",
    "    valErrors = []\n",
    "    degrees = range(2, 5)\n",
    "    minDiff = float('inf')\n",
    "    bestDegree = None\n",
    "    bestR2 = None\n",
    "    bestMSE = None\n",
    "\n",
    "    for degree in degrees:\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        xPolyTrain = poly.fit_transform(xTrain)\n",
    "        xPolyVal = poly.transform(xVal)\n",
    "        learningCurve(model, xPolyTrain, yTrain,degree)\n",
    "        model.fit(xPolyTrain, yTrain)\n",
    "        yPredTrain = model.predict(xPolyTrain)\n",
    "        trainR2 = r2_score(yTrain, yPredTrain)\n",
    "        trainMSE = mean_squared_error(yTrain, yPredTrain)\n",
    "        trainErrors.append([np.log1p(trainR2), np.log1p(trainMSE)])\n",
    "        print(f\"Training R2 Score (Degree {degree}): {trainR2}\")\n",
    "        print(f\"Training MSE (Degree {degree}): {trainMSE}\")\n",
    "\n",
    "        yPredVal = model.predict(xPolyVal)\n",
    "        valR2 = r2_score(yVal, yPredVal)\n",
    "        valMSE = mean_squared_error(yVal, yPredVal)\n",
    "        valErrors.append([np.log1p(valR2), np.log1p(valMSE)])\n",
    "        print(f\"Validation R2 Score (Degree {degree}): {valR2}\")\n",
    "        print(f\"Validation MSE (Degree {degree}): {valMSE}\")\n",
    "        \n",
    "        diff = abs(valR2 - trainR2)\n",
    "        if diff < minDiff:\n",
    "            minDiff = diff\n",
    "            bestDegree = degree\n",
    "            bestR2 = valR2\n",
    "            bestMSE = valMSE\n",
    "\n",
    "    trainErrors = np.array(trainErrors)\n",
    "    valErrors = np.array(valErrors)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degrees, trainErrors[:, 0], label='Train R2 Score', marker='o')\n",
    "    plt.plot(degrees, valErrors[:, 0], label='Validation R2 Score', marker='o')\n",
    "    plt.plot(degrees, trainErrors[:, 1], label='Train MSE', marker='o')\n",
    "    plt.plot(degrees, valErrors[:, 1], label='Validation MSE', marker='o')\n",
    "    plt.xlabel('Degree of Polynomial Features')\n",
    "    plt.ylabel('Error (log scale)')\n",
    "    plt.title('Train and Validation Errors vs. Polynomial Model Complexity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Best Degree: {bestDegree}, Minimum difference: {minDiff}\")\n",
    "    print(f\"Degree ({bestDegree}) R2 Score: {bestR2}\")\n",
    "    print(f\"Degree ({bestDegree}) Mean Squared Error: {bestMSE}\")\n",
    "    return bestDegree,bestR2,bestMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compareRegularization(xTrain, yTrain, xVal, yVal):\n",
    "    bestR2 = -float('inf')\n",
    "    bestMSE = float('inf')\n",
    "    bestAlpha = None\n",
    "    bestType = None\n",
    "\n",
    "    ridgeAlpha, ridgeR2, ridgeMSE = ridgeRegularization(xTrain, yTrain, xVal, yVal)\n",
    "    lassoAlpha, lassoR2, lassoMSE = lassoRegularization(xTrain, yTrain, xVal, yVal)\n",
    "   \n",
    "    # Compare R2 scores\n",
    "    if ridgeR2 > bestR2:\n",
    "        bestR2 = ridgeR2\n",
    "        bestMSE = ridgeMSE\n",
    "        bestAlpha = ridgeAlpha\n",
    "        bestType = \"Ridge\"\n",
    "\n",
    "    elif lassoR2 > bestR2:\n",
    "        bestR2 = lassoR2\n",
    "        bestMSE = lassoMSE\n",
    "        bestAlpha = lassoAlpha\n",
    "        bestType = \"Lasso\"\n",
    "\n",
    "    print(\"\\nBest Model:\", bestType)\n",
    "    print(f\"{bestType} R2 Score: {bestR2}\")\n",
    "    print(f\"{bestType} Mean Squared Error: {bestMSE}\")\n",
    "    return bestType,bestAlpha"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encode\n",
      "After encode\n",
      "Before encode\n",
      "After encode\n",
      "Before encode\n",
      "After encode\n",
      "Before impute\n",
      "After impute\n",
      "Before impute\n",
      "After impute\n",
      "Before scale\n",
      "After scale\n",
      "Before scale\n",
      "After scale\n",
      "Before scale\n",
      "After scale\n",
      "Before scale\n",
      "After scale\n",
      "Before scale\n",
      "After scale\n"
     ]
    }
   ],
   "source": [
    "categoricalFeatures = ['WeekStatus', 'Load_Type', 'Day']\n",
    "featuresWithNan = ['Leading_Current_Reactive_Power_kVarh', 'Leading_Current_Power_Factor']\n",
    "skewedFeatures = ['Lagging_Current_Power_Factor', 'Lagging_Current_Reactive.Power_kVarh'] + featuresWithNan\n",
    "for feature in categoricalFeatures:\n",
    "    encode(feature, xTrain, xVal, xTest)\n",
    "for feature in featuresWithNan:\n",
    "    impute(feature, xTrain, xVal, xTest)\n",
    "for feature in skewedFeatures + ['CO2(tCO2)']:\n",
    "    scale(feature, xTrain, xVal, xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
